# Piano-Generation

This project aims to generate music using neural networks, specifically LSTM models, to predict note pitch and duration. MIDI files from the "Dataset" folder serve as the dataset. The process involves extracting musical information from MIDI files, creating a structured dataframe, and mapping pitches for model input. Three LSTM models are built and compared: one without embedding, one with embedding for notes concatenated with duration, and one predicting only notes using embedding with a fixed duration. Training incorporates a custom batch generation function and manual early stopping and checkpointing. The trained models generate music sequences from a seed, saved as MIDI files and converted to WAV for playback. Models with two outputs are evaluated based on their validation loss and further compared to a model with one output. The subjective quality of the generated music is assessed via audio playback. The project demonstrates the use of LSTM networks for musical sequence generation, highlighting the importance of data pre-processing and model architecture.